<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> What Children Know That AI Doesn't: Learning Through Experience, Not Text (!Work in Progress!) | Debjit Paul </title> <meta name="author" content="Debjit Paul"> <meta name="description" content="Jean Piaget revealed how children construct understanding through action, surprise, and adaptation. His insights expose fundamental gaps in current AI—systems that predict words, not reality."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://debjitpaul.github.io/blog/2025/world-model/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Debjit</span> Paul </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">What Children Know That AI Doesn't: Learning Through Experience, Not Text (!Work in Progress!)</h1> <p class="post-meta"> Created on September 30, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/cognitive-development"> <i class="fa-solid fa-hashtag fa-sm"></i> cognitive-development</a>   <a href="/blog/tag/piaget"> <i class="fa-solid fa-hashtag fa-sm"></i> piaget</a>   <a href="/blog/tag/ai-reasoning"> <i class="fa-solid fa-hashtag fa-sm"></i> ai-reasoning</a>   <a href="/blog/tag/world-models"> <i class="fa-solid fa-hashtag fa-sm"></i> world-models</a>   <a href="/blog/tag/experiential-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> experiential-learning</a>   ·   <a href="/blog/category/research"> <i class="fa-solid fa-tag fa-sm"></i> research</a>   <a href="/blog/category/ai-theory"> <i class="fa-solid fa-tag fa-sm"></i> ai-theory</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>A toddler drops a toy. It falls. They drop it again. By the third time, they predict the fall before releasing. Drop a helium balloon, and watch their delighted confusion—it floats upward instead. This simple interaction contains a profound lesson: the child is building a causal model of gravity through direct experience, learning from genuine surprise when reality violates predictions.</p> <p>Now consider GPT-4. It has “read” millions of descriptions of falling objects and can generate fluent text: “when you drop something, it falls due to gravity.” But it has never experienced releasing an object, never felt acceleration, never been surprised by a balloon floating. It predicts what <em>would be said</em> about dropping objects, not what <em>would actually happen</em>.</p> <p>This distinction—between linguistic pattern matching and genuine causal understanding grounded in experience—reveals why current AI, despite impressive capabilities, lacks true intelligence. Jean Piaget’s theory of cognitive development offers a framework for understanding what’s missing.</p> <h2 id="piagets-core-insight-knowledge-is-constructed-through-experience">Piaget’s Core Insight: Knowledge is Constructed Through Experience</h2> <p>Swiss psychologist Jean Piaget (1896-1980) made a revolutionary claim: children don’t passively absorb knowledge. They actively <strong>construct</strong> understanding through interaction with the world.<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> Knowledge isn’t transmitted—it’s built by the learner through experience, experimentation, and adaptation.</p> <p>This has immediate implications for AI. Current machine learning follows a transmission model: massive datasets encode patterns, models absorb them through optimization. But a child doesn’t need millions of examples to understand gravity—they construct the concept through dozens of hands-on experiments, generalizing from minimal data by building causal models, not memorizing correlations.</p> <h3 id="schemas-testable-mental-models">Schemas: Testable Mental Models</h3> <p>Piaget introduced <strong>schemas</strong>—organized patterns representing our understanding of the world.<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup> A schema isn’t stored knowledge; it’s an active framework for interpreting experiences, making predictions, and recognizing when reality violates expectations.</p> <p>A child’s schema for “dog” includes: four legs, fur, barks. When they encounter a cat, their dog schema fails to predict its behavior (meows, acts aloof), triggering learning. The schema is <strong>testable against reality</strong>.</p> <p>Modern AI has representations—word embeddings, neural activations—but these lack causal structure, predictive power, and testability. They capture statistical patterns, not causal understanding.</p> <h3 id="two-modes-of-learning-assimilation-and-accommodation">Two Modes of Learning: Assimilation and Accommodation</h3> <p><strong>Assimilation</strong>: Fitting new experiences into existing schemas. Seeing a new dog breed: “that’s also a dog.”</p> <p><strong>Accommodation</strong>: Restructuring schemas when experiences don’t fit. Meeting a cat: the child must split their schema—dogs AND cats, both with four legs but different behaviors.<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup></p> <p>Most neural networks only assimilate—fitting new data within existing capacity. When truly novel information arrives, they fail catastrophically, overfit, or suffer catastrophic forgetting. Few AI systems have mechanisms for graceful accommodation—recognizing when their world model is fundamentally wrong and restructuring it while preserving valuable knowledge.</p> <h2 id="the-four-stages-from-action-to-abstraction">The Four Stages: From Action to Abstraction</h2> <p>Piaget proposed that cognitive development progresses through four distinct, universal stages, each characterized by fundamentally different ways of thinking and interacting with the world.<sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">4</a></sup></p> <h3 id="stage-1-sensorimotor-0-2-years">Stage 1: Sensorimotor (0-2 years)</h3> <p>Children learn through direct sensory experience and motor action.<sup id="fnref:5"><a href="#fn:5" class="footnote" rel="footnote" role="doc-noteref">5</a></sup> Key achievement: object permanence—things exist even when unseen. This requires repeated experimentation, sensorimotor feedback, and surprise learning. Infants master causality and object permanence by manipulating their surroundings and learning from the consequences.<sup id="fnref:6"><a href="#fn:6" class="footnote" rel="footnote" role="doc-noteref">6</a></sup></p> <p><strong>For AI</strong>: This is the embodiment problem. Systems trained on text or static images lack sensorimotor grounding, action-consequence loops, and physical intuition. They reason about physics they’ve never experienced.</p> <h3 id="stage-2-preoperational-2-7-years">Stage 2: Preoperational (2-7 years)</h3> <p>Symbolic thinking emerges—using words to represent objects not present.<sup id="fnref:7"><a href="#fn:7" class="footnote" rel="footnote" role="doc-noteref">7</a></sup> But limitations remain: difficulty reversing operations mentally, focusing on one aspect while ignoring others (centration), inability to take others’ perspectives (egocentrism).</p> <p><strong>For AI</strong>: This is where LLMs operate. They manipulate symbols fluently but show systematic limitations—sensitivity to surface features, difficulty with logical reversibility, brittle performance when prompts change slightly.</p> <h3 id="stage-3-concrete-operational-7-11-years">Stage 3: Concrete Operational (7-11 years)</h3> <p>Logical reasoning develops—but only with concrete, tangible examples.<sup id="fnref:8"><a href="#fn:8" class="footnote" rel="footnote" role="doc-noteref">8</a></sup> Children can classify hierarchically, understand conservation (quantity remains constant despite changes in appearance), reverse operations mentally. But they struggle with abstract concepts and hypothetical reasoning.</p> <p><strong>For AI</strong>: Current systems rarely reach this stage. LLMs sometimes simulate logical inference through pattern matching but lack stable, consistent logical frameworks.</p> <h3 id="stage-4-formal-operational-12-years">Stage 4: Formal Operational (12+ years)</h3> <p>Abstract reasoning, hypothesis testing, scientific thinking.<sup id="fnref:9"><a href="#fn:9" class="footnote" rel="footnote" role="doc-noteref">9</a></sup> Understanding abstract concepts, reasoning about hypotheticals, thinking about thinking (metacognition).</p> <p><strong>For AI</strong>: The unreached goal. Even frontier systems show brittle, domain-specific reasoning that doesn’t transfer robustly.</p> <h2 id="three-critical-gaps">Three Critical Gaps</h2> <h3 id="gap-1-experience-vs-description">Gap 1: Experience vs. Description</h3> <p><strong>Piaget</strong>: Knowledge comes from acting on the world and observing consequences. A child learns “hot” by experiencing heat, connecting sensation to cause. Cognitive development emerges from the interaction between the child’s actions and the environment’s responses.<sup id="fnref:10"><a href="#fn:10" class="footnote" rel="footnote" role="doc-noteref">10</a></sup></p> <p><strong>Current AI</strong>: Learns from descriptions of others’ experiences. An LLM has read “fire is hot” millions of times but never experienced heat. It predicts what people <em>say</em> about heat, not what heat actually <em>feels like</em> or <em>causes</em>.</p> <p>As Alan Turing observed, true machine intelligence requires <strong>“machines that can learn from experience, where experience means things that actually happened.”</strong><sup id="fnref:11"><a href="#fn:11" class="footnote" rel="footnote" role="doc-noteref">11</a></sup> Current LLMs lack this experiential grounding—they absorb descriptions, not reality.</p> <h3 id="gap-2-predicting-reality-vs-predicting-words">Gap 2: Predicting Reality vs. Predicting Words</h3> <p><strong>World Models predict what will happen in reality</strong>. A child’s world model: “If I release this, it will fall.” This prediction is tested against reality. When surprised (balloon floats), the model updates.</p> <table> <tbody> <tr> <td> <strong>LLMs predict what would be said about reality</strong>. They model P(next words</td> <td>previous words), not P(outcomes</td> <td>actions). When their linguistic prediction is wrong, they receive no feedback from reality—only more text descriptions, which themselves might be incorrect.</td> </tr> </tbody> </table> <p>Consider:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Child: "If I let go, this will fall"
→ Action: Releases object
→ Reality: Object falls
→ Update: Prediction confirmed

LLM: "Objects fall when dropped"
→ Action: None
→ Reality: No interaction
→ Update: Only from more text
</code></pre></div></div> <p>The LLM’s knowledge is untested and untestable against physical reality.</p> <h3 id="gap-3-learning-from-surprise">Gap 3: Learning from Surprise</h3> <p><strong>Piaget’s deepest insight</strong>: Children learn most when reality violates predictions. The balloon floats (violating gravity schema), ice melts (violating object permanence), the friendly dog bites (violating behavioral schema). Surprise triggers accommodation—the unexpected outcome signals “my model is wrong.”<sup id="fnref:12"><a href="#fn:12" class="footnote" rel="footnote" role="doc-noteref">12</a></sup></p> <p><strong>Current AI cannot be genuinely surprised by reality</strong>. LLMs never interact with the physical world. When deployed, if predictions are wrong, they receive no reality-based feedback—only human corrections encoded as more text. When an LLM confidently predicts something physically impossible, reality never corrects it.</p> <p>This is perhaps the most critical limitation: <strong>without the ability to be surprised by reality, AI cannot truly learn from experience</strong>.</p> <h2 id="what-this-means-for-building-better-ai">What This Means for Building Better AI</h2> <p>Piaget’s framework suggests several principles:</p> <p><strong>Start with embodiment</strong>: Intelligence should be grounded in sensorimotor experience before abstract reasoning. Train agents in physical environments with action-consequence feedback.</p> <p><strong>Enable genuine surprise</strong>: Systems need to form explicit predictions about reality, test them through action, recognize failures, and use surprise as a learning signal.</p> <p><strong>Support accommodation</strong>: Systems need structured representations that can be updated incrementally or restructured fundamentally, avoiding catastrophic forgetting.</p> <p><strong>Progress through stages</strong>: Follow Piaget’s progression—sensorimotor grounding, then symbolic representation, concrete logic, and finally abstract reasoning. Skipping stages creates surface-level capabilities with fundamental limitations.</p> <h2 id="current-work-and-future-directions">Current Work and Future Directions</h2> <p>Recent research begins incorporating these principles. Del Ser et al. (2025) propose a framework integrating six key areas essential for enabling AI systems to develop structured, adaptive representations inspired by Piaget’s cognitive development theory:<sup id="fnref:13"><a href="#fn:13" class="footnote" rel="footnote" role="doc-noteref">13</a></sup></p> <ol> <li> <strong>Physics-informed learning</strong>: Embedding physical laws and constraints</li> <li> <strong>Neurosymbolic AI</strong>: Combining neural pattern recognition with symbolic reasoning</li> <li> <strong>Causal inference</strong>: Modeling interventions and counterfactuals</li> <li> <strong>Open-world machine learning</strong>: Handling novelty and continual learning</li> <li> <strong>Human-in-the-loop</strong>: Guided development with human feedback</li> <li> <strong>Responsible AI</strong>: Ethical constraints and safety considerations</li> </ol> <p>These directions address Piagetian concerns: grounding in physical reality, structured causal representations, accommodation mechanisms, and experiential learning loops. But much work remains in building systems that genuinely construct knowledge through experience rather than absorbing patterns from text.</p> <h2 id="conclusion-the-hard-truth-about-intelligence">Conclusion: The Hard Truth About Intelligence</h2> <p>Current AI development optimizes for benchmark performance and scaling—bigger models, more data. But Piaget’s framework reveals this approach’s limitations:</p> <p><strong>Quantity of text data ≠ Quality of experiential learning</strong></p> <p>A child constructs rich causal understanding from limited but highly informative experiences—each grounded in reality, tied to action and consequence, testable through prediction and surprise. Training on trillions of text tokens provides vast linguistic patterns but no sensorimotor grounding, no action-consequence loops, no reality-based surprise.</p> <p>The challenge isn’t primarily technical—it’s philosophical. We want AI to be precocious, to skip development stages and emerge fully formed. But intelligence doesn’t work that way. Piaget demonstrated that genuine understanding is built slowly through countless interactions, mistakes, accommodation, and gradual construction of ever-more-sophisticated schemas.<sup id="fnref:14"><a href="#fn:14" class="footnote" rel="footnote" role="doc-noteref">14</a></sup></p> <p>If we want AI that truly understands reality rather than mimicking descriptions of it, we must let it learn through genuine experience: hands-on interaction, prediction, surprise, and patient construction of causal models grounded in reality itself.</p> <p>As Turing recognized and Piaget formalized: <strong>machines that truly think must learn from experience—from things that actually happen, not just from reading about what happened</strong>.</p> <hr> <h2 id="references">References</h2> <h3 id="additional-reading">Additional Reading</h3> <ul> <li>Boden, M. A. (1979). <em>Piaget</em>. Fontana/Collins.</li> <li>Brainerd, C. J. (1978). <em>Piaget’s Theory of Intelligence</em>. Prentice-Hall.</li> <li>Ginsburg, H., &amp; Opper, S. (1988). <em>Piaget’s Theory of Intellectual Development</em> (3rd ed.). Prentice-Hall.</li> <li>Lake, B. M., Ullman, T. D., Tenenbaum, J. B., &amp; Gershman, S. J. (2017). “Building machines that learn and think like people.” <em>Behavioral and Brain Sciences</em>, 40, e253.</li> <li>Marcus, G. (2018). “Deep Learning: A Critical Appraisal.” <em>arXiv preprint arXiv:1801.00631</em>.</li> <li>Wikipedia contributors. (2025). “Piaget’s theory of cognitive development.” <em>Wikipedia, The Free Encyclopedia</em>. Retrieved from https://en.wikipedia.org/wiki/Piaget’s_theory_of_cognitive_development</li> </ul> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>Piaget, J. (1954). <em>The Construction of Reality in the Child</em>. Basic Books. [Original work published 1937] <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:2"> <p>Piaget, J. (1952). <em>The Origins of Intelligence in Children</em>. International Universities Press. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:3"> <p>Piaget, J. (1970). <em>Genetic Epistemology</em>. Columbia University Press. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:4"> <p>Piaget, J. (1936). <em>The Origins of Intelligence in the Child</em>. Routledge &amp; Kegan Paul. (See also: Simply Psychology. (2025). “Piaget’s Theory and Stages of Cognitive Development.” Retrieved from https://www.simplypsychology.org/piaget.html) <a href="#fnref:4" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:5"> <p>Piaget, J., &amp; Inhelder, B. (1969). <em>The Psychology of the Child</em>. Basic Books. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:6"> <p>National Center for Biotechnology Information. (2023). “Cognitive Development.” <em>StatPearls</em>. Retrieved from https://www.ncbi.nlm.nih.gov/books/NBK537095/ <a href="#fnref:6" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:7"> <p>Piaget, J. (1959). <em>The Language and Thought of the Child</em> (3rd ed.). Routledge &amp; Kegan Paul. <a href="#fnref:7" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:8"> <p>Piaget, J., &amp; Inhelder, B. (1956). <em>The Child’s Conception of Space</em>. Routledge &amp; Kegan Paul. <a href="#fnref:8" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:9"> <p>Inhelder, B., &amp; Piaget, J. (1958). <em>The Growth of Logical Thinking from Childhood to Adolescence</em>. Basic Books. <a href="#fnref:9" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:10"> <p>Piaget, J. (1970). <em>Piaget’s Theory</em>. In P. H. Mussen (Ed.), <em>Carmichael’s Manual of Child Psychology</em> (Vol. 1, pp. 703-732). Wiley. <a href="#fnref:10" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:11"> <p>Turing, A. M. (1950). “Computing Machinery and Intelligence.” <em>Mind</em>, 59(236), 433-460. <a href="#fnref:11" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:12"> <p>Piaget, J. (1985). <em>The Equilibration of Cognitive Structures: The Central Problem of Intellectual Development</em>. University of Chicago Press. <a href="#fnref:12" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:13"> <p>Del Ser, J., Lobo, J. L., Müller, H., &amp; Holzinger, A. (2025). “World Models in Artificial Intelligence: Sensing, Learning, and Reasoning Like a Child.” <em>arXiv preprint arXiv:2503.15168</em>. Retrieved from https://arxiv.org/abs/2503.15168 <a href="#fnref:13" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:14"> <p>Flavell, J. H. (1963). <em>The Developmental Psychology of Jean Piaget</em>. Van Nostrand. <a href="#fnref:14" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/compute/">Understanding FLOPs, MFU, and Computational Efficiency in LLM Training: From Dense Transformers to MoE Architectures</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/fipo-outstanding-paper-award/">FIPO: Fallacy-Informed Preference Optimization - Steering LLMs Toward Logically Sound Arguments</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/reasoning-matter/">Making Reasoning Matter: Measuring Faithfulness in Chain-of-Thought Reasoning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/">blog</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Debjit Paul. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>